# -*- coding: utf-8 -*-
"""CancerImageDetectionModel

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pNVxrLcYIA2hAnBrmTPzEbETqeFme19V
"""

!pip install kagglehub transformers timm -q


import os, shutil, io, time
import numpy as np
import pandas as pd
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import torch
from torch import nn, optim
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import kagglehub
from tqdm import tqdm
from torch.cuda.amp import autocast, GradScaler
from collections import defaultdict
from google.colab import files
from PIL import Image
import random
from sklearn.metrics import balanced_accuracy_score

# Download dataset
path = kagglehub.dataset_download("obulisainaren/multi-cancer")
data_dir = os.path.join(path, "Multi Cancer", "Multi Cancer")

print("Downloaded path:", path)

def print_dir_structure(base_dir, indent=0):
    for item in os.listdir(base_dir):
        p = os.path.join(base_dir, item)
        print("  " * indent + "- " + item)
        if os.path.isdir(p):
            print_dir_structure(p, indent + 1)

# Setting a random seed to prevent data leakage
seed = random.randint(0, 2**32 - 1)
generator = torch.Generator().manual_seed(seed)

# Image transforms and data loading
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(0.5, 0.6),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

# Adjust path if needed
data_dir = os.path.join(path, "Multi Cancer", "Multi Cancer")
full_dataset = datasets.ImageFolder(root=data_dir, transform=transform)
class_names = full_dataset.classes
print("Classes:", class_names)

val_size = int(0.2 * len(full_dataset))
train_size = len(full_dataset) - val_size
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size], generator)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True, prefetch_factor=2)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True, prefetch_factor=2)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# Gaussian Noise Class
class GaussianNoise(nn.Module):
  def __init__(self, std = 0.01):
    super(GaussianNoise, self).__init__()
    self.std = std

  def forward(self, x):
    if self.training and self.std > 0:
      noise = torch.rand_like(x) * self.std
      return x + noise
    return x

# Gaussian Noise Network

class GaussianCancerClassifier(nn.Module):
  def __init__(self, num_classes=2):
        super(GaussianCancerClassifier, self).__init__()
        self.noise = GaussianNoise(0.1)
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(32)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(64)
        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm2d(64)
        self.pool = nn.AdaptiveMaxPool2d((56, 56))
        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)
        self.dropout = nn.Dropout(0.5)
        self.fc1 = nn.Linear(64, 256)
        self.fc2 = nn.Linear(256, num_classes)

  def forward(self, x):
        x = self.noise(x)
        x = self.pool(torch.relu(self.bn1(self.conv1(x))))
        x = self.pool(torch.relu(self.bn2(self.conv2(x))))
        x = self.pool(torch.relu(self.bn3(self.conv3(x))))
        x = self.global_avg_pool(x)
        x = x.view(x.size(0), -1)
        x = torch.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x

from torchvision import models
class CancerClassifier(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.base_model = models.resnet18(weights='IMAGENET1K_V1')
        for param in self.base_model.parameters():
            param.requires_grad = False
        in_features = self.base_model.fc.in_features
        self.base_model.fc = nn.Sequential(
            nn.Linear(in_features, 256), nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes)
        )
    def forward(self, x):
        return self.base_model(x)

def evaluate(model, loader, device):
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for x, y in loader:
            x, y = x.to(device), y.to(device)
            out = model(x)
            _, pred = torch.max(out, 1)
            all_preds.extend(pred.cpu().numpy())
            all_labels.extend(y.cpu().numpy())

    acc = np.mean(np.array(all_preds) == np.array(all_labels))
    bal_acc = balanced_accuracy_score(all_labels, all_preds)
    return acc, bal_acc

def train_model(model, train_loader, val_loader, num_epochs=10, lr=0.001, device='cuda', patience=3):
    model.to(device)
    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)
    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)
    scaler = GradScaler()

    best_val_acc = 0
    no_improve = 0
    train_losses, train_accs, val_accs = [], [], []

    for epoch in range(num_epochs):
        model.train()
        total_loss, correct, total = 0, 0, 0

        for x, y in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}"):
            x, y = x.to(device), y.to(device)
            optimizer.zero_grad()
            with autocast():
                out = model(x)
                loss = criterion(out, y)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            total_loss += loss.item()
            _, pred = out.max(1)
            correct += (pred == y).sum().item()
            total += y.size(0)

        train_acc = correct / total
        val_acc, val_bal_acc = evaluate(model, val_loader, device)
        print(f"Epoch {epoch+1}: Loss={total_loss:.4f}, Train Acc={train_acc*100:.2f}%, Val Acc={val_acc*100:.2f}%, Balanced Acc={val_bal_acc*100:.2f}%")


        train_losses.append(total_loss)
        train_accs.append(train_acc)
        val_accs.append(val_acc)

        if val_acc > best_val_acc:
            best_val_acc = val_acc
            no_improve = 0
        else:
            no_improve += 1
            if no_improve >= patience:
                print("Early stopping triggered")
                break
        scheduler.step()

    plt.figure(figsize=(12, 4))
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label='Loss')
    plt.title('Training Loss')
    plt.grid(True)

    plt.subplot(1, 2, 2)
    plt.plot(train_accs, label='Train Acc')
    plt.plot(val_accs, label='Val Acc')
    plt.title('Accuracy')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

device = "cuda" if torch.cuda.is_available() else "cpu"
# model = CancerClassifier(num_classes=len(class_names))
model = GaussianCancerClassifier(len(class_names)).to(device)
train_model(model, train_loader, val_loader, num_epochs=5, lr=0.001, device=device, patience=3)

# Visualize Predictions
def visualize_predictions(model, loader, class_names, device, num_images=32):
    model.eval()
    images, labels = next(iter(loader))
    images, labels = images[:num_images].to(device), labels[:num_images].to(device)

    with torch.no_grad():
        outputs = model(images)
        _, preds = torch.max(outputs, 1)

    # Calculate rows and columns for the subplot
    rows = num_images // 5 + int(num_images % 5 != 0)
    cols = min(5, num_images)

    fig, axs = plt.subplots(rows, cols, figsize=(15, 3 * rows))
    axs = axs.flatten() if num_images > 1 else [axs]

    for i in range(num_images):
        img = images[i].cpu().permute(1, 2, 0) * 0.5 + 0.5  # Unnormalize if needed
        axs[i].imshow(img)
        axs[i].set_title(f"Pred: {class_names[preds[i]]}\nTrue: {class_names[labels[i]]}", fontsize=9)
        axs[i].axis('off')

    # Hide any extra axes
    for j in range(num_images, len(axs)):
        axs[j].axis('off')

    plt.tight_layout()
    plt.show()


visualize_predictions(model, val_loader, class_names, device)

import random

def visualize_predictions(model, loader, class_names, device, num_images=32):
    model.eval()

    # Flatten entire dataset into one list of images & labels
    all_images = []
    all_labels = []
    for imgs, lbls in loader:
        all_images.append(imgs)
        all_labels.append(lbls)
    all_images = torch.cat(all_images)
    all_labels = torch.cat(all_labels)

    # Randomly sample indices
    indices = random.sample(range(len(all_images)), min(num_images, len(all_images)))
    images = all_images[indices].to(device)
    labels = all_labels[indices].to(device)

    with torch.no_grad():
        outputs = model(images)
        _, preds = torch.max(outputs, 1)

    # Layout
    rows = num_images // 5 + int(num_images % 5 != 0)
    cols = min(5, num_images)

    fig, axs = plt.subplots(rows, cols, figsize=(15, 3 * rows))
    axs = axs.flatten() if num_images > 1 else [axs]

    for i in range(num_images):
        img = images[i].cpu().permute(1, 2, 0) * 0.5 + 0.5
        axs[i].imshow(img)
        axs[i].set_title(f"Pred: {class_names[preds[i]]}\nTrue: {class_names[labels[i]]}", fontsize=9)
        axs[i].axis('off')

    for j in range(num_images, len(axs)):
        axs[j].axis('off')

    plt.tight_layout()
    plt.show()

visualize_predictions(model, val_loader, class_names, device)

def predict_image(img_path, model, transform, class_names, device, threshold=0.7, entropy_threshold=1.5):
    image = Image.open(img_path).convert('RGB')
    image_tensor = transform(image).unsqueeze(0).to(device)

    model.eval()
    with torch.no_grad():
        outputs = model(image_tensor)
        probs = F.softmax(outputs, dim=1)
        conf, predicted = torch.max(probs, 1)
        ent = -torch.sum(probs * torch.log(probs + 1e-9)).item()

    predicted_class = class_names[predicted.item()]
    conf_score = conf.item()

    print(f"Predicted: {predicted_class}")
    print(f"Confidence: {conf_score:.2f}")
    print(f"Entropy: {ent:.2f}")

    if conf_score < threshold or ent > entropy_threshold:
        print("Model is unsure. May not be a valid cancer image.")

    plt.imshow(Image.open(img_path))
    plt.title(f"{predicted_class} ({conf_score:.2f})", fontsize=12)
    plt.axis('off')
    plt.show()